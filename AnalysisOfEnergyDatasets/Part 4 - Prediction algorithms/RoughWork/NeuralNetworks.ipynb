{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14803, 42)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "df_train=pd.read_csv(\"C:/Users/Akash/Documents/ADS/Assignment2/Appliances-energy-prediction-data-master/training.csv\")\n",
    "df_train['date']=pd.to_datetime(df_train['date'])\n",
    "#df_train['year']=df_train['date'].dt.year\n",
    "df_train['month']=df_train['date'].dt.month\n",
    "df_train['day']=df_train['date'].dt.day\n",
    "df_train['time_hr_24']=df_train['date'].dt.hour\n",
    "df_train['time_min']=df_train['date'].dt.minute\n",
    "morning=range(6,12)\n",
    "afternoon=range(12,17)\n",
    "evening=range(17,22)\n",
    "def time_slot(x):\n",
    "    if x in morning:\n",
    "        return 'morning'\n",
    "    elif x in afternoon:\n",
    "        return 'afternoon'\n",
    "    elif x in evening:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "#df_train['time_slot']=df_train['time_hr_24'].map(time_slot)\n",
    "df_train.drop(['date'],axis=1,inplace=True)\n",
    "df_train=pd.get_dummies(df_train,prefix=['WS','DOW'],columns=['WeekStatus','Day_of_week'])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for training dataset\n",
    "x_train=df_train.iloc[:,1:]\n",
    "y_train=df_train['Appliances']\n",
    "#col_list=['NSM','RH_1','RH_2','T3','RH_3','Press_mm_hg','TS_night','T1','T2','T4','RH_4','T5','RH_5','T6','RH_6',\n",
    "#                      'T7','RH_7','T8','RH_8','RH_9','T_out','RH_out','Windspeed','Tdewpoint']\n",
    "#x_train=x_train[col_list]\n",
    "scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "#x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(280, 280, 280), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(280,280,280),max_iter=500)\n",
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.419674949147\n",
      "MAE  : 40.2604663324\n",
      "RMSE : 78.3307815482\n",
      "MAPE : 40.2324688137\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=mlp.predict(x_train)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "print(\"MAPE :\",mean_absolute_percentage_error(y_train,y_train_pred))\n",
    "#print(confusion_matrix(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for testing dataset\n",
    "df_test=pd.read_csv(\"C:/Users/Akash/Documents/ADS/Assignment2/Appliances-energy-prediction-data-master/testing.csv\")\n",
    "df_test['date']=pd.to_datetime(df_test['date'])\n",
    "#df_test['year']=df_test['date'].dt.year\n",
    "df_test['month']=df_test['date'].dt.month\n",
    "df_test['day']=df_test['date'].dt.day\n",
    "df_test['time_hr_24']=df_test['date'].dt.hour\n",
    "df_test['time_min']=df_test['date'].dt.minute\n",
    "#df_test['time_slot']=df_test['time_hr_24'].map(time_slot)\n",
    "df_test.drop(['date'],axis=1,inplace=True)\n",
    "#df_test.head()\n",
    "df_test=pd.get_dummies(df_test,prefix=['WS','DOW'],columns=['WeekStatus','Day_of_week'])\n",
    "#print(df_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  59.08\n"
     ]
    }
   ],
   "source": [
    "x_test=df_test.iloc[:,1:]\n",
    "#x_test=x_test[col_list]\n",
    "x_test=scaler.transform(x_test)\n",
    "y_test=df_test['Appliances']\n",
    "baseline_errors = abs(96.745742 - y_test)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2))\n",
    "#evaluate(rf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2   : 0.315196153964\n",
      "MAE  : 42.2853378244\n",
      "RMSE : 84.0800622356\n",
      "MAPE : 41.9931921129\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=mlp.predict(x_test)\n",
    "print(\"R2   :\",r2_score(y_test,y_test_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_test,y_test_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_test,y_test_pred)))\n",
    "print(\"MAPE :\",mean_absolute_percentage_error(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(50,50,50),(140,140,140), (210,210,210)],\n",
    "'alpha': [10.0 ** -np.arange(1, 7)],\n",
    "'solver' : [\"lbfgs\",\"sgd\", \"adam\"],\n",
    "'activation': [ \"relu\", \"Tanh\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_params() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-403-b4b25f36986d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmlp_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    560\u001b[0m                                          n_candidates * len(cv)))\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     58\u001b[0m                             % (repr(estimator), type(estimator)))\n\u001b[0;32m     59\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mnew_object_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_params() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "mlp_grid=GridSearchCV(estimator=MLPRegressor,param_grid=parameters,n_jobs=-1,verbose=2,cv=3)\n",
    "mlp_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-400-056ca8289ca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R2   :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAE  :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RMSE :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAPE :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \"\"\"\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "y_train_pred=mlp_grid.predict(x_train)\n",
    "print(\"R2   :\",r2_score(y_train,y_train_pred))\n",
    "print(\"MAE  :\",mean_absolute_error(y_train,y_train_pred))\n",
    "print(\"RMSE :\",np.sqrt(mean_squared_error(y_train,y_train_pred)))\n",
    "print(\"MAPE :\",mean_absolute_percentage_error(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13814, 46)\n",
      "(5921, 46)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "weekend = ['Saturday','Sunday']\n",
    "def week_day_type(x):\n",
    "    if x in weekend:\n",
    "        return 'weekends'\n",
    "    else:\n",
    "        return 'weekdays'\n",
    "def time_slot(x):\n",
    "    if x in morning:\n",
    "        return 'morning'\n",
    "    elif x in afternoon:\n",
    "        return 'afternoon'\n",
    "    elif x in evening:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'  \n",
    "df=pd.read_csv(\"C:/Users/Akash/Documents/ADS/Assignment2/Appliances-energy-prediction-data-master/energydata_complete.csv\")\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df['year']=df['date'].dt.year\n",
    "df['month']=df['date'].dt.month\n",
    "df['day']=df['date'].dt.day\n",
    "df['day_of_week']=df['date'].dt.weekday_name\n",
    "df['time_hr_24']=df['date'].dt.hour\n",
    "df['time_min']=df['date'].dt.minute\n",
    "df['week_day_type']=df['day_of_week'].map(week_day_type)\n",
    "morning=range(6,12)\n",
    "afternoon=range(12,17)\n",
    "evening=range(17,22)  \n",
    "df['time_slot']=df['time_hr_24'].map(time_slot)\n",
    "df.drop(['date'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(df,prefix=['DOW','TS','WDT'],columns=['day_of_week','time_slot','week_day_type'])\n",
    "df_train,df_test = train_test_split(df,train_size=0.7,random_state=42)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=df_train.iloc[:,1:]\n",
    "#print(x_train.shape)\n",
    "y_train=df_train['Appliances']\n",
    "scaler.fit(x_train)\n",
    "x_train_sc=scaler.transform(x_train)\n",
    "x_test=df_test.iloc[:,1:]\n",
    "y_test=df_test['Appliances']\n",
    "x_test_sc=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000026011307ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000026011307ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 15, 1, 36, 13, 157690, tzinfo=tzutc()), 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'session': '2F88409B0817485482D3B8655CB004CD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2F88409B0817485482D3B8655CB004CD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 15, 1, 36, 13, 157690, tzinfo=tzutc()), 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'session': '2F88409B0817485482D3B8655CB004CD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2F88409B0817485482D3B8655CB004CD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 15, 1, 36, 13, 157690, tzinfo=tzutc()), 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'session': '2F88409B0817485482D3B8655CB004CD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-8-43cab1ead4b5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 26018e80f28, executio..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000260199DBD20, file \"<ipython-input-8-43cab1ead4b5>\", line 9>\n        result = <ExecutionResult object at 26018e80f28, executio..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000260199DBD20, file \"<ipython-input-8-43cab1ead4b5>\", line 9>, result=<ExecutionResult object at 26018e80f28, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000260199DBD20, file \"<ipython-input-8-43cab1ead4b5>\", line 9>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', '10.0 ** -np.arange(1, 7)', 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)'], 'MLPRegressor': <class 'sklearn.neural_network.multilayer_perceptron.MLPRegressor'>, 'Out': {4: array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SCORERS': {'accuracy': make_scorer(accuracy_score), 'adjusted_mutual_info_score': make_scorer(adjusted_mutual_info_score), 'adjusted_rand_score': make_scorer(adjusted_rand_score), 'average_precision': make_scorer(average_precision_score, needs_threshold=True), 'completeness_score': make_scorer(completeness_score), 'explained_variance': make_scorer(explained_variance_score), 'f1': make_scorer(f1_score), 'f1_macro': make_scorer(f1_score, pos_label=None, average=macro), 'f1_micro': make_scorer(f1_score, pos_label=None, average=micro), 'f1_samples': make_scorer(f1_score, pos_label=None, average=samples), ...}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), '_4': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', '10.0 ** -np.arange(1, 7)', 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)'], 'MLPRegressor': <class 'sklearn.neural_network.multilayer_perceptron.MLPRegressor'>, 'Out': {4: array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SCORERS': {'accuracy': make_scorer(accuracy_score), 'adjusted_mutual_info_score': make_scorer(adjusted_mutual_info_score), 'adjusted_rand_score': make_scorer(adjusted_rand_score), 'average_precision': make_scorer(average_precision_score, needs_threshold=True), 'completeness_score': make_scorer(completeness_score), 'explained_variance': make_scorer(explained_variance_score), 'f1': make_scorer(f1_score), 'f1_macro': make_scorer(f1_score, pos_label=None, average=macro), 'f1_micro': make_scorer(f1_score, pos_label=None, average=micro), 'f1_samples': make_scorer(f1_score, pos_label=None, average=samples), ...}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), '_4': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Akash\\Documents\\ADS\\Assignment2\\<ipython-input-8-43cab1ead4b5> in <module>()\n      4 'alpha': [1.00000000e-01,   1.00000000e-02,   1.00000000e-03, 1.00000000e-04,   1.00000000e-05,   1.00000000e-06],\n      5 'solver' : [\"lbfgs\",\"sgd\", \"adam\"],\n      6 'activation': [ \"relu\", \"Tanh\"]\n      7 }\n      8 mlp_grid=GridSearchCV(estimator=MLPRegressor(),param_grid=parameters,n_jobs=-1,verbose=2,cv=3)\n----> 9 mlp_grid.fit(x_train_sc, y_train)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring=None, verbose=2), X=array([[-0.4771991 , -0.11605938, -1.16951306, .... -0.70887349,\n        -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=2)>\n        X = array([[-0.4771991 , -0.11605938, -1.16951306, .... -0.70887349,\n        -1.61222531,  1.61222531]])\n        y = 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64\n        self.param_grid = {'activation': ['relu', 'Tanh'], 'alpha': [0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06], 'hidden_layer_sizes': [(50, 50, 50), (140, 140, 140), (210, 210, 210)], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'solver': ['lbfgs', 'sgd', 'adam']}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring=None, verbose=2), X=array([[-0.4771991 , -0.11605938, -1.16951306, .... -0.70887349,\n        -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Mar 14 21:36:42 2018\nPID: 16800                Python 3.6.3: C:\\Users\\Akash\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), test=array([   0,    1,    2, ..., 4602, 4603, 4604]), verbose=2, parameters={'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1689                              \" numeric value. (Hint: if using 'raise', please\"\n   1690                              \" make sure that it has been spelled correctly.)\"\n   1691                              )\n   1692 \n   1693     else:\n-> 1694         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        scorer = <function _passthrough_scorer>\n   1695         if return_train_score:\n   1696             train_score = _score(estimator, X_train, y_train, scorer)\n   1697 \n   1698     scoring_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X_test=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y_test=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, scorer=<function _passthrough_scorer>)\n   1746 def _score(estimator, X_test, y_test, scorer):\n   1747     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n   1748     if y_test is None:\n   1749         score = scorer(estimator, X_test)\n   1750     else:\n-> 1751         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n   1752     if hasattr(score, 'item'):\n   1753         try:\n   1754             # e.g. unwrap memmapped scalars\n   1755             score = score.item()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), *args=(memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method RegressorMixin.score of MLPRegress...ion=0.1,\n       verbose=False, warm_start=False)>\n        args = (memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64)\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, sample_weight=None)\n    382             R^2 of self.predict(X) wrt. y.\n    383         \"\"\"\n    384 \n    385         from .metrics import r2_score\n    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n--> 387                         multioutput='variance_weighted')\n    388 \n    389 \n    390 ###############################################################################\n    391 class ClusterMixin(object):\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in r2_score(y_true=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')\n    525     >>> y_pred = [3,2,1]\n    526     >>> r2_score(y_true, y_pred)\n    527     -3.0\n    528     \"\"\"\n    529     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 530         y_true, y_pred, multioutput)\n        y_true = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n        multioutput = 'variance_weighted'\n    531 \n    532     if sample_weight is not None:\n    533         sample_weight = column_or_1d(sample_weight)\n    534         weight = sample_weight[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in _check_reg_targets(y_true=array([ 50,  30,  40, ...,  50,  60, 110], dtype=int64), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1694, in _fit_and_score\n    test_score = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1751, in _score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 244, in _passthrough_scorer\n    return estimator.score(*args, **kwargs)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 387, in score\n    multioutput='variance_weighted')\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\", line 530, in r2_score\n    y_true, y_pred, multioutput)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\", line 77, in _check_reg_targets\n    y_pred = check_array(y_pred, ensure_2d=False)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 453, in check_array\n    _assert_all_finite(array)\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 44, in _assert_all_finite\n    \" or a value too large for %r.\" % X.dtype)\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Mar 14 21:36:42 2018\nPID: 16800                Python 3.6.3: C:\\Users\\Akash\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), test=array([   0,    1,    2, ..., 4602, 4603, 4604]), verbose=2, parameters={'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1689                              \" numeric value. (Hint: if using 'raise', please\"\n   1690                              \" make sure that it has been spelled correctly.)\"\n   1691                              )\n   1692 \n   1693     else:\n-> 1694         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        scorer = <function _passthrough_scorer>\n   1695         if return_train_score:\n   1696             train_score = _score(estimator, X_train, y_train, scorer)\n   1697 \n   1698     scoring_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X_test=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y_test=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, scorer=<function _passthrough_scorer>)\n   1746 def _score(estimator, X_test, y_test, scorer):\n   1747     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n   1748     if y_test is None:\n   1749         score = scorer(estimator, X_test)\n   1750     else:\n-> 1751         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n   1752     if hasattr(score, 'item'):\n   1753         try:\n   1754             # e.g. unwrap memmapped scalars\n   1755             score = score.item()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), *args=(memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method RegressorMixin.score of MLPRegress...ion=0.1,\n       verbose=False, warm_start=False)>\n        args = (memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64)\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, sample_weight=None)\n    382             R^2 of self.predict(X) wrt. y.\n    383         \"\"\"\n    384 \n    385         from .metrics import r2_score\n    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n--> 387                         multioutput='variance_weighted')\n    388 \n    389 \n    390 ###############################################################################\n    391 class ClusterMixin(object):\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in r2_score(y_true=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')\n    525     >>> y_pred = [3,2,1]\n    526     >>> r2_score(y_true, y_pred)\n    527     -3.0\n    528     \"\"\"\n    529     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 530         y_true, y_pred, multioutput)\n        y_true = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n        multioutput = 'variance_weighted'\n    531 \n    532     if sample_weight is not None:\n    533         sample_weight = column_or_1d(sample_weight)\n    534         weight = sample_weight[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in _check_reg_targets(y_true=array([ 50,  30,  40, ...,  50,  60, 110], dtype=int64), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Mar 14 21:36:42 2018\nPID: 16800                Python 3.6.3: C:\\Users\\Akash\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), test=array([   0,    1,    2, ..., 4602, 4603, 4604]), verbose=2, parameters={'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1689                              \" numeric value. (Hint: if using 'raise', please\"\n   1690                              \" make sure that it has been spelled correctly.)\"\n   1691                              )\n   1692 \n   1693     else:\n-> 1694         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        scorer = <function _passthrough_scorer>\n   1695         if return_train_score:\n   1696             train_score = _score(estimator, X_train, y_train, scorer)\n   1697 \n   1698     scoring_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X_test=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y_test=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, scorer=<function _passthrough_scorer>)\n   1746 def _score(estimator, X_test, y_test, scorer):\n   1747     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n   1748     if y_test is None:\n   1749         score = scorer(estimator, X_test)\n   1750     else:\n-> 1751         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n   1752     if hasattr(score, 'item'):\n   1753         try:\n   1754             # e.g. unwrap memmapped scalars\n   1755             score = score.item()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), *args=(memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method RegressorMixin.score of MLPRegress...ion=0.1,\n       verbose=False, warm_start=False)>\n        args = (memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64)\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, sample_weight=None)\n    382             R^2 of self.predict(X) wrt. y.\n    383         \"\"\"\n    384 \n    385         from .metrics import r2_score\n    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n--> 387                         multioutput='variance_weighted')\n    388 \n    389 \n    390 ###############################################################################\n    391 class ClusterMixin(object):\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in r2_score(y_true=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')\n    525     >>> y_pred = [3,2,1]\n    526     >>> r2_score(y_true, y_pred)\n    527     -3.0\n    528     \"\"\"\n    529     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 530         y_true, y_pred, multioutput)\n        y_true = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n        multioutput = 'variance_weighted'\n    531 \n    532     if sample_weight is not None:\n    533         sample_weight = column_or_1d(sample_weight)\n    534         weight = sample_weight[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in _check_reg_targets(y_true=array([ 50,  30,  40, ...,  50,  60, 110], dtype=int64), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-43cab1ead4b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      8\u001b[0m \u001b[0mmlp_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmlp_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000026011307ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000026011307ED0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 15, 1, 36, 13, 157690, tzinfo=tzutc()), 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'session': '2F88409B0817485482D3B8655CB004CD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2F88409B0817485482D3B8655CB004CD']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 15, 1, 36, 13, 157690, tzinfo=tzutc()), 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'session': '2F88409B0817485482D3B8655CB004CD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2F88409B0817485482D3B8655CB004CD'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 15, 1, 36, 13, 157690, tzinfo=tzutc()), 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'session': '2F88409B0817485482D3B8655CB004CD', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'C4927AC36CC4414B9450ECF67902BEF8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-8-43cab1ead4b5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 26018e80f28, executio..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000260199DBD20, file \"<ipython-input-8-43cab1ead4b5>\", line 9>\n        result = <ExecutionResult object at 26018e80f28, executio..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000260199DBD20, file \"<ipython-input-8-43cab1ead4b5>\", line 9>, result=<ExecutionResult object at 26018e80f28, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000260199DBD20, file \"<ipython-input-8-43cab1ead4b5>\", line 9>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', '10.0 ** -np.arange(1, 7)', 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)'], 'MLPRegressor': <class 'sklearn.neural_network.multilayer_perceptron.MLPRegressor'>, 'Out': {4: array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SCORERS': {'accuracy': make_scorer(accuracy_score), 'adjusted_mutual_info_score': make_scorer(adjusted_mutual_info_score), 'adjusted_rand_score': make_scorer(adjusted_rand_score), 'average_precision': make_scorer(average_precision_score, needs_threshold=True), 'completeness_score': make_scorer(completeness_score), 'explained_variance': make_scorer(explained_variance_score), 'f1': make_scorer(f1_score), 'f1_macro': make_scorer(f1_score, pos_label=None, average=macro), 'f1_micro': make_scorer(f1_score, pos_label=None, average=micro), 'f1_samples': make_scorer(f1_score, pos_label=None, average=samples), ...}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), '_4': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', '10.0 ** -np.arange(1, 7)', 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...-1,verbose=2,cv=3)\\nmlp_grid.fit(x_train, y_train)', 'import pandas as pd\\nimport datetime\\nimport numpy...te=42)\\nprint(df_train.shape)\\nprint(df_test.shape)', \"x_train=df_train.iloc[:,1:]\\n#print(x_train.shape...['Appliances']\\nx_test_sc=scaler.transform(x_test)\", 'parameters={\\n\\'learning_rate\\': [\"constant\", \"invs...verbose=2,cv=3)\\nmlp_grid.fit(x_train_sc, y_train)'], 'MLPRegressor': <class 'sklearn.neural_network.multilayer_perceptron.MLPRegressor'>, 'Out': {4: array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SCORERS': {'accuracy': make_scorer(accuracy_score), 'adjusted_mutual_info_score': make_scorer(adjusted_mutual_info_score), 'adjusted_rand_score': make_scorer(adjusted_rand_score), 'average_precision': make_scorer(average_precision_score, needs_threshold=True), 'completeness_score': make_scorer(completeness_score), 'explained_variance': make_scorer(explained_variance_score), 'f1': make_scorer(f1_score), 'f1_macro': make_scorer(f1_score, pos_label=None, average=macro), 'f1_micro': make_scorer(f1_score, pos_label=None, average=micro), 'f1_samples': make_scorer(f1_score, pos_label=None, average=samples), ...}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, '_': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), '_4': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Akash\\Documents\\ADS\\Assignment2\\<ipython-input-8-43cab1ead4b5> in <module>()\n      4 'alpha': [1.00000000e-01,   1.00000000e-02,   1.00000000e-03, 1.00000000e-04,   1.00000000e-05,   1.00000000e-06],\n      5 'solver' : [\"lbfgs\",\"sgd\", \"adam\"],\n      6 'activation': [ \"relu\", \"Tanh\"]\n      7 }\n      8 mlp_grid=GridSearchCV(estimator=MLPRegressor(),param_grid=parameters,n_jobs=-1,verbose=2,cv=3)\n----> 9 mlp_grid.fit(x_train_sc, y_train)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring=None, verbose=2), X=array([[-0.4771991 , -0.11605938, -1.16951306, .... -0.70887349,\n        -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=2)>\n        X = array([[-0.4771991 , -0.11605938, -1.16951306, .... -0.70887349,\n        -1.61222531,  1.61222531]])\n        y = 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64\n        self.param_grid = {'activation': ['relu', 'Tanh'], 'alpha': [0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06], 'hidden_layer_sizes': [(50, 50, 50), (140, 140, 140), (210, 210, 210)], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'solver': ['lbfgs', 'sgd', 'adam']}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring=None, verbose=2), X=array([[-0.4771991 , -0.11605938, -1.16951306, .... -0.70887349,\n        -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Mar 14 21:36:42 2018\nPID: 16800                Python 3.6.3: C:\\Users\\Akash\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), 9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, <function _passthrough_scorer>, array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), array([   0,    1,    2, ..., 4602, 4603, 4604]), 2, {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n         -1.61222531,  1.61222531]]), y=9129      50\n2453      30\n9152      40\n12694    ...130\nName: Appliances, Length: 13814, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 4605,  4606,  4607, ..., 13811, 13812, 13813]), test=array([   0,    1,    2, ..., 4602, 4603, 4604]), verbose=2, parameters={'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'constant', 'solver': 'sgd'}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1689                              \" numeric value. (Hint: if using 'raise', please\"\n   1690                              \" make sure that it has been spelled correctly.)\"\n   1691                              )\n   1692 \n   1693     else:\n-> 1694         test_score = _score(estimator, X_test, y_test, scorer)\n        test_score = undefined\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        scorer = <function _passthrough_scorer>\n   1695         if return_train_score:\n   1696             train_score = _score(estimator, X_train, y_train, scorer)\n   1697 \n   1698     scoring_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _score(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X_test=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y_test=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, scorer=<function _passthrough_scorer>)\n   1746 def _score(estimator, X_test, y_test, scorer):\n   1747     \"\"\"Compute the score of an estimator on a given test set.\"\"\"\n   1748     if y_test is None:\n   1749         score = scorer(estimator, X_test)\n   1750     else:\n-> 1751         score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False)\n        X_test = memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]])\n        y_test = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n   1752     if hasattr(score, 'item'):\n   1753         try:\n   1754             # e.g. unwrap memmapped scalars\n   1755             score = score.item()\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), *args=(memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method RegressorMixin.score of MLPRegress...ion=0.1,\n       verbose=False, warm_start=False)>\n        args = (memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64)\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=MLPRegressor(activation='relu', alpha=0.1, batch...tion=0.1,\n       verbose=False, warm_start=False), X=memmap([[-0.4771991 , -0.11605938, -1.16951306, ...-0.70887349,\n          0.6202607 , -0.6202607 ]]), y=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, sample_weight=None)\n    382             R^2 of self.predict(X) wrt. y.\n    383         \"\"\"\n    384 \n    385         from .metrics import r2_score\n    386         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n--> 387                         multioutput='variance_weighted')\n    388 \n    389 \n    390 ###############################################################################\n    391 class ClusterMixin(object):\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in r2_score(y_true=9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64, y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), sample_weight=None, multioutput='variance_weighted')\n    525     >>> y_pred = [3,2,1]\n    526     >>> r2_score(y_true, y_pred)\n    527     -3.0\n    528     \"\"\"\n    529     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n--> 530         y_true, y_pred, multioutput)\n        y_true = 9129      50\n2453      30\n9152      40\n12694    ... 110\nName: Appliances, Length: 4605, dtype: int64\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n        multioutput = 'variance_weighted'\n    531 \n    532     if sample_weight is not None:\n    533         sample_weight = column_or_1d(sample_weight)\n    534         weight = sample_weight[:, np.newaxis]\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py in _check_reg_targets(y_true=array([ 50,  30,  40, ...,  50,  60, 110], dtype=int64), y_pred=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), multioutput='variance_weighted')\n     72         correct keyword.\n     73 \n     74     \"\"\"\n     75     check_consistent_length(y_true, y_pred)\n     76     y_true = check_array(y_true, ensure_2d=False)\n---> 77     y_pred = check_array(y_pred, ensure_2d=False)\n        y_pred = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n     78 \n     79     if y_true.ndim == 1:\n     80         y_true = y_true.reshape((-1, 1))\n     81 \n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]), accept_sparse=False, dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=False, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    448             array = array.astype(np.float64)\n    449         if not allow_nd and array.ndim >= 3:\n    450             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n    451                              % (array.ndim, estimator_name))\n    452         if force_all_finite:\n--> 453             _assert_all_finite(array)\n        array = array([ nan,  nan,  nan, ...,  nan,  nan,  nan])\n    454 \n    455     shape_repr = _shape_repr(array.shape)\n    456     if ensure_min_samples > 0:\n    457         n_samples = _num_samples(array)\n\n...........................................................................\nC:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py in _assert_all_finite(X=array([ nan,  nan,  nan, ...,  nan,  nan,  nan]))\n     39     # everything is finite; fall back to O(n) space np.isfinite to prevent\n     40     # false positives from overflow in sum method.\n     41     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n     42             and not np.isfinite(X).all()):\n     43         raise ValueError(\"Input contains NaN, infinity\"\n---> 44                          \" or a value too large for %r.\" % X.dtype)\n        X.dtype = dtype('float64')\n     45 \n     46 \n     47 def assert_all_finite(X):\n     48     \"\"\"Throw a ValueError if X contains NaN or infinity.\n\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "parameters={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(50,50,50),(140,140,140),(210,210,210)],\n",
    "'alpha': [1.00000000e-01,   1.00000000e-02,   1.00000000e-03, 1.00000000e-04,   1.00000000e-05,   1.00000000e-06],\n",
    "'solver' : [\"lbfgs\",\"sgd\", \"adam\"],\n",
    "'activation': [ \"relu\", \"Tanh\"]\n",
    "}\n",
    "mlp_grid=GridSearchCV(estimator=MLPRegressor(),param_grid=parameters,n_jobs=-1,verbose=2,cv=3)\n",
    "mlp_grid.fit(x_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-01,   1.00000000e-02,   1.00000000e-03,\n",
       "         1.00000000e-04,   1.00000000e-05,   1.00000000e-06])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.0 ** -np.arange(1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lights             int64\n",
       "T1               float64\n",
       "RH_1             float64\n",
       "T2               float64\n",
       "RH_2             float64\n",
       "T3               float64\n",
       "RH_3             float64\n",
       "T4               float64\n",
       "RH_4             float64\n",
       "T5               float64\n",
       "RH_5             float64\n",
       "T6               float64\n",
       "RH_6             float64\n",
       "T7               float64\n",
       "RH_7             float64\n",
       "T8               float64\n",
       "RH_8             float64\n",
       "T9               float64\n",
       "RH_9             float64\n",
       "T_out            float64\n",
       "Press_mm_hg      float64\n",
       "RH_out           float64\n",
       "Windspeed        float64\n",
       "Visibility       float64\n",
       "Tdewpoint        float64\n",
       "rv1              float64\n",
       "rv2              float64\n",
       "year               int64\n",
       "month              int64\n",
       "day                int64\n",
       "time_hr_24         int64\n",
       "time_min           int64\n",
       "DOW_Friday         uint8\n",
       "DOW_Monday         uint8\n",
       "DOW_Saturday       uint8\n",
       "DOW_Sunday         uint8\n",
       "DOW_Thursday       uint8\n",
       "DOW_Tuesday        uint8\n",
       "DOW_Wednesday      uint8\n",
       "TS_afternoon       uint8\n",
       "TS_evening         uint8\n",
       "TS_morning         uint8\n",
       "TS_night           uint8\n",
       "WDT_weekdays       uint8\n",
       "WDT_weekends       uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
